{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Unified SR Model Training on Kaggle\n",
                "\n",
                "This notebook trains the Unified SR Model using the **STARE** (Medical), **Tuberculosis** (Medical), and **SpaceNet 2** (Satellite) datasets.\n",
                "\n",
                "## Workflow\n",
                "1.  **Setup**: Copy code and install dependencies.\n",
                "2.  **Data Preparation**: \n",
                "    *   We will read the raw images from Kaggle Input.\n",
                "    *   We will generate Low-Resolution (LR) images and create a Validation split for the Medical dataset.\n",
                "    *   All processed data will be stored in `/kaggle/working/data`.\n",
                "3.  **Training**: Train the model using the processed data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import cv2\n",
                "import numpy as np\n",
                "import random\n",
                "from glob import glob\n",
                "import torch\n",
                "\n",
                "# Check GPU\n",
                "print(f\"GPU Available: {torch.cuda.is_available()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Paths\n",
                "**IMPORTANT**: Verify these paths match your Kaggle Input structure."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# INPUT PATHS (Adjust if needed)\n",
                "# STARE Dataset\n",
                "MEDICAL_RAW_PATH = '/kaggle/input/stare-dataset' \n",
                "\n",
                "# Tuberculosis Dataset\n",
                "TB_RAW_PATH = '/kaggle/input/tuberculosis-chest-xrays-shenzhen'\n",
                "\n",
                "# SpaceNet 2 Dataset\n",
                "SATELLITE_RAW_PATH = '/kaggle/input/spacenet-2-paris-buildings' \n",
                "\n",
                "# OUTPUT PATH (Working Directory)\n",
                "BASE_DATA_DIR = '/kaggle/working/data'\n",
                "CODE_DIR = '/kaggle/input/unified-sr-code' # Where you uploaded src/ and train.py"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copy Code to Working Directory\n",
                "if os.path.exists(CODE_DIR):\n",
                "    if os.path.exists('/kaggle/working/src'):\n",
                "        shutil.rmtree('/kaggle/working/src')\n",
                "    shutil.copytree(os.path.join(CODE_DIR, 'src'), '/kaggle/working/src')\n",
                "    shutil.copy(os.path.join(CODE_DIR, 'train.py'), '/kaggle/working/train.py')\n",
                "    print(\"Code copied to /kaggle/working\")\n",
                "else:\n",
                "    print(\"WARNING: Code directory not found. Make sure you added the 'unified-sr-code' dataset.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Preprocessing\n",
                "We need to:\n",
                "1.  Resize HR images to 128x128.\n",
                "2.  Generate LR images (32x32).\n",
                "3.  Split Medical data into Train/Val (80/20)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def preprocess_image(img_path, save_hr_path, save_lr_path, scale=4, size=(128, 128)):\n",
                "    img = cv2.imread(img_path)\n",
                "    if img is None: return False\n",
                "    \n",
                "    # Resize HR\n",
                "    hr_img = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
                "    \n",
                "    # Generate LR\n",
                "    h, w = hr_img.shape[:2]\n",
                "    lr_img = cv2.resize(hr_img, (w // scale, h // scale), interpolation=cv2.INTER_CUBIC)\n",
                "    \n",
                "    # Save\n",
                "    basename = os.path.basename(img_path)\n",
                "    cv2.imwrite(os.path.join(save_hr_path, f\"resized_{basename}\"), hr_img)\n",
                "    cv2.imwrite(os.path.join(save_lr_path, basename), lr_img)\n",
                "    return True\n",
                "\n",
                "def process_dataset(raw_path, out_train_dir, out_val_dir, is_medical=False, split_ratio=0.8):\n",
                "    # Find all images\n",
                "    exts = ('*.ppm', '*.png', '*.jpg', '*.tif')\n",
                "    files = []\n",
                "    for ext in exts:\n",
                "        files.extend(glob(os.path.join(raw_path, '**', ext), recursive=True))\n",
                "    \n",
                "    print(f\"Found {len(files)} images in {raw_path}\")\n",
                "    if not files: return\n",
                "    \n",
                "    random.shuffle(files)\n",
                "    \n",
                "    # Determine Split\n",
                "    if is_medical:\n",
                "        # Medical: Split raw files into Train/Val\n",
                "        split_idx = int(len(files) * split_ratio)\n",
                "        train_files = files[:split_idx]\n",
                "        val_files = files[split_idx:]\n",
                "    else:\n",
                "        # Satellite\n",
                "        split_idx = int(len(files) * split_ratio)\n",
                "        train_files = files[:split_idx]\n",
                "        val_files = files[split_idx:]\n",
                "\n",
                "    # Process Train\n",
                "    print(f\"Processing {len(train_files)} Train images...\")\n",
                "    os.makedirs(os.path.join(out_train_dir, 'hr'), exist_ok=True)\n",
                "    os.makedirs(os.path.join(out_train_dir, 'lr'), exist_ok=True)\n",
                "    for f in train_files:\n",
                "        preprocess_image(f, os.path.join(out_train_dir, 'hr'), os.path.join(out_train_dir, 'lr'))\n",
                "\n",
                "    # Process Val\n",
                "    print(f\"Processing {len(val_files)} Val images...\")\n",
                "    os.makedirs(os.path.join(out_val_dir, 'hr'), exist_ok=True)\n",
                "    os.makedirs(os.path.join(out_val_dir, 'lr'), exist_ok=True)\n",
                "    for f in val_files:\n",
                "        preprocess_image(f, os.path.join(out_val_dir, 'hr'), os.path.join(out_val_dir, 'lr'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run Processing\n",
                "# Medical (STARE)\n",
                "if os.path.exists(MEDICAL_RAW_PATH):\n",
                "    process_dataset(\n",
                "        MEDICAL_RAW_PATH, \n",
                "        os.path.join(BASE_DATA_DIR, 'medical', 'train'), \n",
                "        os.path.join(BASE_DATA_DIR, 'medical', 'val'), \n",
                "        is_medical=True\n",
                "    )\n",
                "\n",
                "# Medical (TB)\n",
                "if os.path.exists(TB_RAW_PATH):\n",
                "    print(\"Processing TB Dataset...\")\n",
                "    process_dataset(\n",
                "        TB_RAW_PATH, \n",
                "        os.path.join(BASE_DATA_DIR, 'medical', 'train'), \n",
                "        os.path.join(BASE_DATA_DIR, 'medical', 'val'), \n",
                "        is_medical=True\n",
                "    )\n",
                "\n",
                "# Satellite\n",
                "process_dataset(\n",
                "    SATELLITE_RAW_PATH, \n",
                "    os.path.join(BASE_DATA_DIR, 'satelitte', 'train'), \n",
                "    os.path.join(BASE_DATA_DIR, 'satelitte', 'val'), \n",
                "    is_medical=False\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python train.py \\\n",
                "    --epochs 50 \\\n",
                "    --batch_size 16 \\\n",
                "    --lr 0.0001 \\\n",
                "    --scale 4 \\\n",
                "    --medical_data {BASE_DATA_DIR}/medical \\\n",
                "    --satellite_data {BASE_DATA_DIR}/satelitte \\\n",
                "    --save_dir checkpoints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Zip the checkpoints folder for easier download\n",
                "!zip -r checkpoints.zip checkpoints\n",
                "\n",
                "from IPython.display import FileLink\n",
                "import os\n",
                "\n",
                "if os.path.exists('checkpoints.zip'):\n",
                "    display(FileLink(r'checkpoints.zip'))\n",
                "else:\n",
                "    print(\"Error: checkpoints.zip not found. Training might have failed.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}